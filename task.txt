1) В нашем проекте весь деплой кода просиходит на виртуалки - здесь минимально изучаем VirtualBox.
Установить VirtualBox 6.1, выделить новой виртуалке под диск 20 Гб ( диск динамический, это верхний предел, после установки
он будет весить 5-8 Гб), 2 Гб RAM, 1 core CPU. Установить на виртуалку Xubuntu 18 отсюда
https://mirror.yandex.ru/ubuntu-cdimage/xubuntu/releases/18.04.5/release/

Установить через apt: chromium browser, python3, chromedriver
apt install chromium-browser
apt install chromium-chromedriver
Установить pip install selenium , запустить на виртуалке тестовый браузер chromium + Selenium.

2) Нужно сделать простой однопоточный парсер/лайкер инстаграма с очередью задач в базе. В таблице tasks есть очередь заданий
со статусами (новое, в процессе, выполнено, ошибка). Парсер берет из очереди в БД задание, на время выполнения помечает
его "в процессе", после выполнения - выполнено/ошибка. Парсер работает с базой postgres либо mysql, напрямую с SQL запросами.
Лучше, если парсер будет реализован отдельно, без джанги. Парсер разворачиваем на ВМ Xubuntu 18 из 1)

2.1) Парсер запускает Selenium браузер Chromium, по пути из settings берется хром профиль, с которым он будет работать:
chrome_options.add_argument('--user-data-dir={}'.format(settings.full_profile))
Хром профиль в папке settings.full_profile позволяет не проходить авторизацию каждый раз заново, он сохранит инста куки до следующего запуска.

2.2) При запуске парсер проверяет, авторизован ли он в инсте (по содержимому страницы/инста не требует логина) - если нет,
авторизуется по логину/паролю из settings (челленджей "код на почту" итд - пока проходим вручную). Парсер запускается с одним и
тем же хром профилем, чтобы не делать логин слишком часто (это приведет к челленджам "код на почту" итд). Вначале можно сделать
логин вручную (запустить хромиум с --user-data-dir /path/to/chrom/profile, залогиниться, потом запускать с тем же хром профилем).

2.3) В таблице задачи есть поля "профиль", "число постов Н", после взятия задачи - парсер переходит на указанный в БД профиль,
подписывается на профиль. Далее по очереди переходит на верхние Н постов в профиле. Из каждого поста парсится число лайков,
дата поста - пишет в колонки в таблицу "Посты", каждому посту ставит лайк. Ставит статус задачи готово/ошибка по результату задачи.
Число лайков, дата поста парсится либо на основе XPath, либо на регекспах.

2.4) Если в БД нет новых задач - сидит в цикле с паузой 5 сек, браузер остается открытым, проверяет БД на предмет новых задач.
При получении новой задачи процесс повторяется с 2.2.

3) REST микросервис для добавления и чтения задач парсера. Может быть реализован на Flask , или на Django. У микросервиса 2 эндпоинта JSON:
POST /create_task , profile=[insta_login], postsN=[N] - создать новую задачу на подписку/лайк/парсинг insta_login
GET /tasks [status=new|progress|done] - показать все задачи в базе, либо задачи только указанным статусом status (если задан этот GET-параметр)
GET /posts - показать все посты из БД, с task_id, числом лайков и датой публикации
Фронтенд к микросервису не нужен, авторизация тоже не нужна, проверять будем с помощью curl. Микросервис развернут на той же виртуальной машине, что и парсер/лайкер на Selenium.

4) Развернуть п.2), 3) на виртуалке с Ubuntu из 1), подготовить к тестированию, дать веб-доступ к АПИ через ssh-туннель.

Таким образом, микросервису можно запушить несколько задач по 1 через /create_task, парсер их выполняет последовательно,
помечает в БД статусы, заполняет Посты с лайками/датой публикации. Через микросервис можно увидеть список задач /tasks.

Тестовый аккаунт инсты для парсера (можно временно привязать к нему свою почту, если инста потребует челлендж код на почту - проходим вручную):
andrew_instaman / q1w2E#R$T%